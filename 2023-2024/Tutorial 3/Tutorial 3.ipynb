{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3adf1fb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tutorial 3\n",
    "\n",
    "**Credits**: Federico Ruggeri, Eleonora Mancini, Paolo Torroni\n",
    "\n",
    "**Keywords**: Transformers, Huggingface, Prompting, LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30acbc3",
   "metadata": {
    "id": "m3wzWLL-LiKd",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Contact\n",
    "\n",
    "For any doubt, question, issue or help, you can always contact us at the following email addresses:\n",
    "\n",
    "Teaching Assistants:\n",
    "\n",
    "* Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
    "* Eleonora Mancini -> e.mancini@unibo.it\n",
    "\n",
    "Professor:\n",
    "\n",
    "* Paolo Torroni -> p.torroni@unibo.it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44dadc7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PART 0 ($\\sim$5 mins)\n",
    "*   Downloading a **dataset**.\n",
    "*   Encoding a a **dataset**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f10c45",
   "metadata": {
    "id": "gl48Am5trp3Y",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PART I ($\\sim$30 mins)\n",
    "\n",
    "*   Text encoding with transformers.\n",
    "*   Model definition.\n",
    "*   Model training and evaluation with huggingface APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1762696",
   "metadata": {
    "id": "D4anSmM4rp3Z",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PART II ($\\sim$30 mins)\n",
    "\n",
    "*   TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86860b11",
   "metadata": {
    "id": "c4-E45fvrp3Z",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Preliminaries\n",
    "\n",
    "First of all, we need to import some useful packages that we will use during this hands-on session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2305467f",
   "metadata": {
    "id": "rUXZLYya69wc",
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# system packages\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import urllib\n",
    "import tarfile\n",
    "import sys\n",
    "\n",
    "# data and numerical management packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# useful during debugging (progress bars)\n",
    "from tqdm import tqdm\n",
    "\n",
    "# typing\n",
    "from typing import List, Callable, Dict, Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9ac9d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frgg/deasy_env/lib/python3.7/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f0eeca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch                             1.13.0+cu116\n",
      "torchdata                         0.5.0\n",
      "torchtext                         0.14.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7301b767",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.13.0+cu116 in /home/frgg/deasy_env/lib/python3.7/site-packages (1.13.0+cu116)\n",
      "Requirement already satisfied: typing-extensions in /home/frgg/deasy_env/lib/python3.7/site-packages (from torch==1.13.0+cu116) (4.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: transformers in /home/frgg/deasy_env/lib/python3.7/site-packages (4.30.2)\n",
      "Requirement already satisfied: filelock in /home/frgg/deasy_env/lib/python3.7/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/frgg/deasy_env/lib/python3.7/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/frgg/deasy_env/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/frgg/deasy_env/lib/python3.7/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/frgg/deasy_env/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/frgg/deasy_env/lib/python3.7/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in /home/frgg/deasy_env/lib/python3.7/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/frgg/deasy_env/lib/python3.7/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/frgg/deasy_env/lib/python3.7/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/frgg/deasy_env/lib/python3.7/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/frgg/deasy_env/lib/python3.7/site-packages (from transformers) (6.0.0)\n",
      "Requirement already satisfied: fsspec in /home/frgg/deasy_env/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/frgg/deasy_env/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/frgg/deasy_env/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/frgg/deasy_env/lib/python3.7/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/frgg/deasy_env/lib/python3.7/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/frgg/deasy_env/lib/python3.7/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/frgg/deasy_env/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: datasets in /home/frgg/deasy_env/lib/python3.7/site-packages (2.13.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/frgg/deasy_env/lib/python3.7/site-packages (from datasets) (1.21.6)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/frgg/deasy_env/lib/python3.7/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/frgg/deasy_env/lib/python3.7/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /home/frgg/deasy_env/lib/python3.7/site-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/frgg/deasy_env/lib/python3.7/site-packages (from datasets) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/frgg/deasy_env/lib/python3.7/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: xxhash in /home/frgg/deasy_env/lib/python3.7/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/frgg/deasy_env/lib/python3.7/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/frgg/deasy_env/lib/python3.7/site-packages (from datasets) (2023.1.0)\n",
      "Requirement already satisfied: aiohttp in /home/frgg/deasy_env/lib/python3.7/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /home/frgg/deasy_env/lib/python3.7/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: packaging in /home/frgg/deasy_env/lib/python3.7/site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/frgg/deasy_env/lib/python3.7/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/frgg/deasy_env/lib/python3.7/site-packages (from datasets) (6.0.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/frgg/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/frgg/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/frgg/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/frgg/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/frgg/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/frgg/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/frgg/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /home/frgg/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/frgg/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets) (4.5.0)\n",
      "Requirement already satisfied: filelock in /home/frgg/deasy_env/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/frgg/deasy_env/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/frgg/deasy_env/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/frgg/deasy_env/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/frgg/deasy_env/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.13.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/frgg/deasy_env/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/frgg/deasy_env/lib/python3.7/site-packages (from pandas->datasets) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/frgg/deasy_env/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: accelerate in /home/frgg/deasy_env/lib/python3.7/site-packages (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/frgg/deasy_env/lib/python3.7/site-packages (from accelerate) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/frgg/deasy_env/lib/python3.7/site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: psutil in /home/frgg/deasy_env/lib/python3.7/site-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: pyyaml in /home/frgg/deasy_env/lib/python3.7/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/frgg/deasy_env/lib/python3.7/site-packages (from accelerate) (1.13.0+cu116)\n",
      "Requirement already satisfied: typing-extensions in /home/frgg/deasy_env/lib/python3.7/site-packages (from torch>=1.6.0->accelerate) (4.5.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.13.0+cu116\n",
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85a3743",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': 2560,\n",
    "        'height': 1440,\n",
    "        'scroll': True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7e6309a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov  3 14:19:45 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| N/A   36C    P0    N/A /  80W |      6MiB /  8192MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      2242      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef8f7c0",
   "metadata": {
    "id": "qImKj2Mu7LCX",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data\n",
    "\n",
    "We will use the IMDB dataset first introduced in tutorial 1.\n",
    "\n",
    "* [**Stats**] A dataset of 50k sentences used for sentiment analysis: 25k with positive sentiment, 25k with negative one.\n",
    "* [**Sentiment**] We consider sentiment labels for classification.\n",
    "\n",
    "We start by **downloading** the dataset and **extract** it to a folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268c2b55",
   "metadata": {
    "id": "NSvqBcKJ7iTY",
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "        \n",
    "def download_url(download_path: Path, url: str):\n",
    "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        urllib.request.urlretrieve(url, filename=download_path, reporthook=t.update_to)\n",
    "\n",
    "        \n",
    "def download_dataset(download_path: Path, url: str):\n",
    "    print(\"Downloading dataset...\")\n",
    "    download_url(url=url, download_path=download_path)\n",
    "    print(\"Download complete!\")\n",
    "\n",
    "def extract_dataset(download_path: Path, extract_path: Path):\n",
    "    print(\"Extracting dataset... (it may take a while...)\")\n",
    "    with tarfile.open(download_path) as loaded_tar:\n",
    "        loaded_tar.extractall(extract_path)\n",
    "    print(\"Extraction completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d62435",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "url = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "dataset_name = \"aclImdb\"\n",
    "\n",
    "print(f\"Current work directory: {Path.cwd()}\")\n",
    "dataset_folder = Path.cwd().joinpath(\"Datasets\")\n",
    "\n",
    "if not dataset_folder.exists():\n",
    "    dataset_folder.mkdir(parents=True)\n",
    "\n",
    "dataset_tar_path = dataset_folder.joinpath(\"Movies.tar.gz\")\n",
    "dataset_path = dataset_folder.joinpath(dataset_name)\n",
    "\n",
    "if not dataset_tar_path.exists():\n",
    "    download_dataset(dataset_tar_path, url)\n",
    "\n",
    "if not dataset_path.exists():\n",
    "    extract_dataset(dataset_tar_path, dataset_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdbb37a",
   "metadata": {
    "id": "pv3NW1SNrp3a",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Data Format\n",
    "\n",
    "Just like in the first assignment, we need a **high level view** of the dataset that is helpful to our needs. \n",
    "\n",
    "We encode the dataset into a [pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adf0a63",
   "metadata": {
    "id": "P05YfYCe7qCj",
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dataframe_rows = []\n",
    "\n",
    "for split in ['train', 'test']:\n",
    "    for sentiment in ['pos', 'neg']:\n",
    "        folder = dataset_folder.joinpath(dataset_name, split, sentiment)\n",
    "        for file_path in folder.glob('*.txt'):            \n",
    "            with file_path.open(mode='r', encoding='utf-8') as text_file:\n",
    "                text = text_file.read()\n",
    "                score = file_path.stem.split(\"_\")[1]\n",
    "                score = int(score)\n",
    "                file_id = file_path.stem.split(\"_\")[0]\n",
    "\n",
    "                num_sentiment = 1 if sentiment == 'pos' else 0\n",
    "\n",
    "                dataframe_row = {\n",
    "                    \"file_id\": file_id,\n",
    "                    \"score\": score,\n",
    "                    \"sentiment\": num_sentiment,\n",
    "                    \"split\": split,\n",
    "                    \"text\": text\n",
    "                }\n",
    "\n",
    "                dataframe_rows.append(dataframe_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec9321",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "folder = Path.cwd().joinpath(\"Datasets\", \"Dataframes\", dataset_name)\n",
    "if not folder.exists():\n",
    "    folder.mkdir(parents=True)\n",
    "\n",
    "# transform the list of rows in a proper dataframe\n",
    "df = pd.DataFrame(dataframe_rows)\n",
    "df = df[[\"file_id\", \n",
    "         \"score\",\n",
    "         \"sentiment\",\n",
    "         \"split\",\n",
    "         \"text\"]\n",
    "       ]\n",
    "df_path = folder.with_name(dataset_name + \".pkl\")\n",
    "df.to_pickle(df_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a185f8",
   "metadata": {
    "id": "Bjf3k-qVrp3b",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PART I\n",
    "\n",
    "*   Text encoding with Transformers.\n",
    "*   Model definition.\n",
    "*   Model training and evaluation with huggingface APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039a51f0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 1. Text encoding with Transformers.\n",
    "\n",
    "In tutorial 1, we have seen how to define standard machine learning models to address sentiment classification.\n",
    "\n",
    "However, we know that Transformer-based models are one of the strongest baselines when assessing a task or benchmarking on a novel corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33067d25",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Before defining our transformer-based classifier, we need to encode text inputs into numerical format.\n",
    "\n",
    "As in Tutorial 1, we are going to **tokenize** input texts to perform token indexing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f720fda",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.1 Encoding the dataset\n",
    "\n",
    "First, we are going to use ``datasets`` library to encode our dataset into a handy wrapper for computational speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20f06bc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_df = df.loc[df['split'] == \"train\"].sample(frac=1.0)[:5000]\n",
    "test_df = df.loc[df['split'] == \"test\"].sample(frac=1.0)[:1000]\n",
    "\n",
    "train_data = Dataset.from_pandas(train_df)\n",
    "test_data = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3462b9fc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's inspect the newly defined `Dataset` instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf57dd1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a46d5a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.1 Transformer Tokenizer\n",
    "\n",
    "Transformers typically use [SentencePiece tokenizer](https://github.com/google/sentencepiece) to perform sub-word level tokenization.\n",
    "\n",
    "In particular, the `transformers` library offers the `AutoTokenizer` class to quickly retrieve our chosen transformer's ad-hoc tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44595edb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_card = 'distilbert-base-uncased'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_card)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec8c600",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The `model_card` variable defines the *path* where to look for our pre-trained model.\n",
    "\n",
    "You can check [huggingface's hub](https://huggingface.co/models) model hub to pick the model card according to your preference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ce3faf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We proceed on tokenizing movie reviews text with our tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22969ad0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_text(texts: Iterable[str]):\n",
    "    return tokenizer(texts['text'], truncation=True)\n",
    "\n",
    "train_data = train_data.map(preprocess_text, batched=True)\n",
    "test_data = test_data.map(preprocess_text, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da82c94",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's inspect the preprocess `Dataset` instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d6b460",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1729211",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(train_data['input_ids'][50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9324da",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(train_data['attention_mask'][50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cbe39b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can perform some quick 'sanity check' to evaluate the tokenization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7c878d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "original_text = train_data['text'][50]\n",
    "decoded_text = tokenizer.decode(train_data['input_ids'][50])\n",
    "\n",
    "print(original_text)\n",
    "print()\n",
    "print()\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650431ca",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Vocabulary\n",
    "\n",
    "We **do not** necessarily need to build a vocabulary since transformers already come with their own! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0863ee66",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**However**, it is still possible to add new tokens to the vocabulary to adapt the model to the given use case.\n",
    "\n",
    "```\n",
    "tokenizer.add_tokens(new_tokens=new_tokens)\n",
    "```\n",
    "\n",
    "The transformer vocabulary will update its **unusued** vocabulary indexes with newly provided tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9b0c55",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Special tokens\n",
    "\n",
    "**Pay attention** to used special tokens and their corresponding token ids.\n",
    "\n",
    "Each transformer models has its own special tokens ([CLS], [SEP], [PAD], [EOS], etc...).\n",
    "\n",
    "Thus, the same special token may be mapped to different token ids in distinct transformer models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513e203e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Text cleaning\n",
    "\n",
    "We didn't perform any kind of text cleaning before performing text encoding.\n",
    "\n",
    "This is usually because transformer tokenizers have their own text cleaning process to perform tokenization and models **may be sensitive** to custom operations!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8fbc80",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "`bert-base-uncased` is trained with text in lower format.\n",
    "\n",
    "**Check model cards** on huggingface to know more about the models you use and inspect their text encoding pipeline to understand how they behave."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df975a08",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Homework 📖\n",
    "\n",
    "Experiment with different model cards.\n",
    "\n",
    "Experiment with text cleaning and evaluate its impact on classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a331dd42",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Model definition\n",
    "\n",
    "We are now ready to define our transformer-based classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf143c3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 2.1 Data Formatting\n",
    "\n",
    "We first need to format input data to be fed as mini-batches in a training/evaluation procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955dca33",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba03005b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The ``DataCollatorWithPadding`` receives a batch of\n",
    "\n",
    "```\n",
    "(input_ids, attention_mask, token_type_ids, label)\n",
    "```\n",
    "\n",
    "tuples and **dynamically pads** ``input_ids``, ``attention_mask`` and ``token_type_ids`` to maximum sequence in the batch. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28deb2da",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Intuitively, this operation saves a lot of memory compared to padding to global maximum sequence, while it introduces a reasonable computational overhead.\n",
    "\n",
    "### Note\n",
    "\n",
    "The above example is just one way out of many to perform dynamic batch padding: it really depends on which data structures you are using."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93106b3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 2.2 Model definition\n",
    "\n",
    "Defining a transformer-based model with huggingface is pretty straightforward!\n",
    "\n",
    "Since we are dealing with text classification, we can use off-the-shelf `AutoModelForSequenceClassification`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a23fd54",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_card,\n",
    "                                                           num_labels=2,\n",
    "                                                           id2label={0: 'NEG', 1: 'POS'},\n",
    "                                                           label2id={'NEG': 0, 'POS': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3cacb5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's first check the loaded model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9474b446",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a73ae7c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**That's it!**\n",
    "\n",
    "That's the simplicity of huggingface's APIs.\n",
    "\n",
    "The model is ready to use for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a7dff5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Custom architectures\n",
    "\n",
    "There are plenty of pre-defined model architectures $\\rightarrow$ [auto classes](https://huggingface.co/docs/transformers/model_doc/auto)\n",
    "\n",
    "In more complex scenarios, we may want to define a custom architecture where the pre-trained model is part of it.\n",
    "\n",
    "In these cases, the way you do it strongly depends on the underlying neural library.\n",
    "\n",
    "However, there exist several high-level APIs depending on your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79825da",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 3. Model training and evaluation\n",
    "\n",
    "We are now ready to define the training and evaluation procedures to test our model on the IMDB dataset.\n",
    "\n",
    "In particular, we are going to use ``Trainer`` APIs to efficiently perform training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d60ece",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.1 Metrics\n",
    "\n",
    "First, we define classification metrics for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c352438",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def compute_metrics(output_info):\n",
    "    predictions, labels = output_info\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    \n",
    "    f1 = f1_score(y_pred=predictions, y_true=labels, average='macro')\n",
    "    acc = accuracy_score(y_pred=predictions, y_true=labels)\n",
    "    return {'f1': f1, 'acc': acc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506ffabd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.2 Training Arguments\n",
    "\n",
    "The ``Trainer`` object can be extensively customized.\n",
    "\n",
    "Feel free to check the [documentation](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments) on training arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba742520",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We first rename the `sentiment` column to `label` as the default input to `AutoModelForSequenceClassification`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632180d4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_data = train_data.rename_column('sentiment', 'label')\n",
    "test_data = test_data.rename_column('sentiment', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c66bf3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_dir\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3afb0b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3b513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3321bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75174013",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06465328",
   "metadata": {
    "id": "UbzMCMfprp3m",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The End!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
